{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install face_recognition"
      ],
      "metadata": {
        "id": "p_HbTSIhFz82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "9SEnW3_8F7OE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjtnZQkTu6tX",
        "outputId": "ce3086b2-282a-44f8-a77d-6b5ff6b2263d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount our google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOQWtSEi5LZ6",
        "outputId": "686a5cd9-6b6c-42d2-c05b-121b08283633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_mp4_files(directory):\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mp4\"):\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "directories = [\n",
        "    '/content/drive/MyDrive/Final Year Project/DFDC_Dataset',\n",
        "    '/content/drive/MyDrive/Final Year Project/DFDC_FAKE_Face_only_data',\n",
        "    '/content/drive/MyDrive/Final Year Project/DFDC_REAL_Face_only_data',\n",
        "    '/content/drive/MyDrive/Final Year Project/DFDC_sample_face_only_data',\n",
        "    '/content/drive/MyDrive/Final Year Project/test_videos',\n",
        "    '/content/drive/MyDrive/Final Year Project/validation_set'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    count = count_mp4_files(directory)\n",
        "    print(f'Number of .mp4 files in {directory}: {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDgFTNAc7Jes",
        "outputId": "2ff5ec70-6e24-44bf-a9da-a0aa0b7db312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of .mp4 files in /content/drive/MyDrive/Final Year Project/DFDC_Dataset: 400\n",
            "Number of .mp4 files in /content/drive/MyDrive/Final Year Project/DFDC_FAKE_Face_only_data: 1566\n",
            "Number of .mp4 files in /content/drive/MyDrive/Final Year Project/DFDC_REAL_Face_only_data: 1727\n",
            "Number of .mp4 files in /content/drive/MyDrive/Final Year Project/DFDC_sample_face_only_data: 0\n",
            "Number of .mp4 files in /content/drive/MyDrive/Final Year Project/test_videos: 400\n",
            "Number of .mp4 files in /content/drive/MyDrive/Final Year Project/validation_set: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "U7lEuUCTGkAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4y_fGlmur4v"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Videos Dataset"
      ],
      "metadata": {
        "id": "GQwvgVzNPFp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the video files\n",
        "video_files_path = '/content/drive/MyDrive/Final Year Project/DFDC_Dataset/train_sample_videos/*.mp4'\n",
        "video_files = glob.glob(video_files_path)"
      ],
      "metadata": {
        "id": "NmVJNtWmO_Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average Frame Count"
      ],
      "metadata": {
        "id": "2ZWjag-tEs4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the frame counts\n",
        "frame_count = []\n",
        "\n",
        "# Iterate over each video file\n",
        "for video_file in video_files:\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Check if the video has less than 150 frames, skip if so\n",
        "    if num_frames < 150:\n",
        "        continue\n",
        "\n",
        "    frame_count.append(num_frames)\n",
        "    cap.release()  # Release the video capture object\n",
        "\n",
        "# Calculate and print the total number of videos and the average frame count\n",
        "print(\"frames\", frame_count)\n",
        "print(\"Total number of videos:\", len(frame_count))\n",
        "if frame_count:\n",
        "    average_frames = np.mean(frame_count)\n",
        "    print('Average frame per video:', average_frames)\n",
        "else:\n",
        "    print('No videos with more than 150 frames found.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIbQeEdwH2q-",
        "outputId": "804c7adc-36c4-452b-e49d-f8f26dd34bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frames [300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300]\n",
            "Total number of videos: 400\n",
            "Average frame per video: 299.935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frame Extraction"
      ],
      "metadata": {
        "id": "vONT1e9IGZsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U92Ovn3JvV52"
      },
      "outputs": [],
      "source": [
        "# Function to extract frames from a video file\n",
        "def frame_extract(path):\n",
        "    vidObj = cv2.VideoCapture(path)  # Open the video file\n",
        "    success = 1\n",
        "    while success:\n",
        "        success, image = vidObj.read()  # Read the next frame\n",
        "        if success:\n",
        "            yield image  # Yield the frame if read successfully"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frames Processing"
      ],
      "metadata": {
        "id": "EpzDYIeAHKb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process video files, detect faces, and save the face images as separate video files\n",
        "def create_face_videos(path_list, out_dir):\n",
        "    # Ensure the output directory exists, create if it does not\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    # Check how many videos are already processed and present in the output directory\n",
        "    already_present_count = glob.glob(os.path.join(out_dir, '*.mp4'))\n",
        "    print(\"No of videos already present:\", len(already_present_count))\n",
        "\n",
        "    # Process each video file in the provided list\n",
        "    for path in tqdm(path_list):\n",
        "        out_path = os.path.join(out_dir, os.path.basename(path))  # Define the output video file path\n",
        "\n",
        "        # Skip processing if the output file already exists\n",
        "        if os.path.exists(out_path):\n",
        "            print(\"File Already exists:\", out_path)\n",
        "            continue\n",
        "\n",
        "        # Prepare to write the output video with the detected faces\n",
        "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
        "\n",
        "        frames = []  # List to hold a batch of frames for batch face detection\n",
        "        for idx, frame in enumerate(frame_extract(path)):\n",
        "            if idx <= 150:  # Limit the processing to the first 150 frames\n",
        "                frames.append(frame)  # Add the frame to the batch\n",
        "                # Perform batch face detection for efficiency\n",
        "                if len(frames) == 4:  # Check if we have enough frames for a batch\n",
        "                    faces = face_recognition.batch_face_locations(frames)  # Detect faces in the batch\n",
        "                    for i, face_locations in enumerate(faces):\n",
        "                        for face in face_locations:  # Iterate through each detected face\n",
        "                            top, right, bottom, left = face\n",
        "                            try:\n",
        "                                # Extract the face region, resize it, and write to the output video\n",
        "                                out.write(cv2.resize(frames[i][top:bottom, left:right, :], (112,112)))\n",
        "                            except Exception as e:\n",
        "                                print(\"Error processing frame:\", e)\n",
        "                    frames = []  # Clear the frame list after processing a batch\n",
        "\n",
        "        out.release()  # Release the video writer"
      ],
      "metadata": {
        "id": "mqeuh3MxKg-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of video paths\n",
        "path_list = video_files\n",
        "# Define the output directory\n",
        "out_dir = '/content/drive/MyDrive/Final Year Project/DFDC_sample_face_only_data'\n",
        "\n",
        "# Process the videos to extract faces and save them\n",
        "create_face_videos(path_list, out_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg_pVO1sMzNr",
        "outputId": "ef37a871-d6a4-4747-bf2a-f32bd7b9f583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of videos already present: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 138/400 [1:57:15<3:43:04, 51.08s/it]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}